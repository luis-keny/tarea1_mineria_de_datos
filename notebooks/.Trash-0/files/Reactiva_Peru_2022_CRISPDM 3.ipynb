{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5df9dd",
   "metadata": {},
   "source": [
    "# Análisis multivariado - Reactiva Perú 2022\n",
    "\n",
    "**Autores:** Luis Lucero, Dayvis Quispe\n",
    "\n",
    "**Fuente de datos (2022):** https://www.mef.gob.pe/contenidos/archivos-descarga/REACTIVA_Lista_beneficiarios_270422.xlsx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53719ffd",
   "metadata": {},
   "source": [
    "### 1. Importación y preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import os, re, unicodedata, warnings, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, roc_curve, auc)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "print(\"Versiones -> pandas:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de dataset\n",
    "# Edita 'dataset_path' si tu archivo está en otra ruta o con otro nombre.\n",
    "# Si lo dejas vacío, intentaremos detectar automáticamente un Excel que contenga 'reactiva' en /mnt/data\n",
    "dataset_path = \"\"  # ejemplo: \"/mnt/data/reactiva_peru_2022.xlsx\"\n",
    "\n",
    "def find_dataset(default_hint=\"reactiva\"):\n",
    "    candidates = []\n",
    "    for root, _, files in os.walk(\"/mnt/data\"):\n",
    "        for f in files:\n",
    "            if f.lower().endswith((\".xlsx\", \".xls\")) and default_hint in f.lower():\n",
    "                candidates.append(os.path.join(root, f))\n",
    "    return sorted(candidates)\n",
    "\n",
    "if not dataset_path or not os.path.exists(dataset_path):\n",
    "    candidates = find_dataset()\n",
    "    if candidates:\n",
    "        dataset_path = candidates[0]\n",
    "\n",
    "if not dataset_path or not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(\"No se encontró el dataset. Edita 'dataset_path' con la ruta correcta.\")\n",
    "\n",
    "print(\"Usando dataset:\", dataset_path)\n",
    "\n",
    "# Leer Excel\n",
    "df = pd.read_excel(dataset_path)\n",
    "print(\"Dimensiones:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarización de nombres y alias (tildes/variantes)\n",
    "def slug(s):\n",
    "    s = (unicodedata.normalize(\"NFKD\", str(s))\n",
    "         .encode(\"ascii\", \"ignore\").decode(\"ascii\"))\n",
    "    s = re.sub(r\"[^0-9a-zA-Z]+\", \"_\", s).strip(\"_\").lower()\n",
    "    return s\n",
    "\n",
    "df.columns = [slug(c) for c in df.columns]\n",
    "\n",
    "# Diccionario de alias -> claves canónicas (soporta tildes/variantes)\n",
    "alias = {\n",
    "    \"repro\": [\"repro\"],\n",
    "    \"sector_economico\": [\"sector_economico\", \"sector_economico_\", \"sector_economico__\"],\n",
    "    \"departamento\": [\"departamento\"],\n",
    "    \"entidad_otorgante_credito\": [\n",
    "        \"entidad_otorgante_credito\",\n",
    "        \"nombre_de_entidad_otorgante_del_credito\",\n",
    "        \"entidad_otorgante_del_credito\"\n",
    "    ],\n",
    "    \"saldo_insoluto\": [\n",
    "        \"saldo_insoluto\", \"saldo_insoluto_s\"\n",
    "    ],\n",
    "    \"cobertura_saldo_insoluto\": [\n",
    "        \"cobertura_del_saldo_insoluto_s\", \"cobertura_saldo_insoluto\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Construimos un mapa de renombrado canónico\n",
    "rename_map = {}\n",
    "present = set(df.columns)\n",
    "for canon, variants in alias.items():\n",
    "    for v in variants:\n",
    "        if v in present:\n",
    "            rename_map[v] = canon\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "print(\"Columnas (estandarizadas):\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ce569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo REPRO (SI/NO -> 1/0) y conversión de numéricos\n",
    "if \"repro\" in df.columns:\n",
    "    if df[\"repro\"].dtype == object:\n",
    "        vals = df[\"repro\"].astype(str).str.strip().str.upper()\n",
    "        df[\"repro\"] = vals.map({\"SI\": 1, \"NO\": 0}).fillna(pd.to_numeric(vals, errors=\"coerce\"))\n",
    "    df[\"repro\"] = pd.to_numeric(df[\"repro\"], errors=\"coerce\")\n",
    "else:\n",
    "    print(\"⚠️ Falta la columna 'REPRO' (o alias). No se podrá entrenar el modelo.\")\n",
    "\n",
    "# Conversión numérica de métricas monetarias si existen\n",
    "for num_col in [\"saldo_insoluto\", \"cobertura_saldo_insoluto\"]:\n",
    "    if num_col in df.columns:\n",
    "        if df[num_col].dtype == object:\n",
    "            # Quita separadores de miles y maneja decimales\n",
    "            df[num_col] = (df[num_col].astype(str)\n",
    "                           .str.replace(r\"[\\s\\,](?=\\d{3}(?:\\D|$))\", \"\", regex=True)\n",
    "                           .str.replace(\",\", \".\", regex=False))\n",
    "        df[num_col] = pd.to_numeric(df[num_col], errors=\"coerce\")\n",
    "\n",
    "# Vista rápida\n",
    "display(df.head())\n",
    "df.describe(include=\"all\").T.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a261cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación (Spearman) entre numéricos de interés\n",
    "num_pair = [\"saldo_insoluto\", \"cobertura_saldo_insoluto\"]\n",
    "if all(col in df.columns for col in num_pair):\n",
    "    spearman = df[num_pair].corr(method=\"spearman\").iloc[0, 1]\n",
    "    print(\"Correlación Spearman saldo_insoluto vs cobertura_saldo_insoluto:\", spearman)\n",
    "else:\n",
    "    print(\"No se pudo calcular la correlación solicitada; faltan columnas:\", [c for c in num_pair if c not in df.columns])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab66349",
   "metadata": {},
   "source": [
    "### 2. Analisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde78e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Distribución REPRO (tabla + gráfico circular)\n",
    "if \"repro\" in df.columns:\n",
    "    counts = df[\"repro\"].value_counts(dropna=False).sort_index()\n",
    "    print(\"Distribución REPRO (0/1):\")\n",
    "    print(counts)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    labels = counts.index.astype(str)\n",
    "    sizes = counts.values\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(\"Porcentaje de empresas con REPRO\")\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Sin 'repro', se omite el gráfico circular.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e97bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Frecuencia de empresas por DEPARTAMENTO (gráfico de barras)\n",
    "if \"departamento\" in df.columns:\n",
    "    freq_depa = df[\"departamento\"].value_counts()\n",
    "    print(freq_depa.head())\n",
    "\n",
    "    fig = plt.figure()\n",
    "    freq_depa.sort_values(ascending=True).plot(kind=\"barh\")\n",
    "    plt.title(\"Frecuencia de empresas según región (Departamento)\")\n",
    "    plt.xlabel(\"Frecuencia de empresas\")\n",
    "    plt.ylabel(\"Región\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Porcentajes\n",
    "    perc_depa = (freq_depa / freq_depa.sum() * 100).sort_values(ascending=True)\n",
    "    fig = plt.figure()\n",
    "    perc_depa.plot(kind=\"barh\")\n",
    "    for i, v in enumerate(perc_depa.values):\n",
    "        plt.text(v, i, f\"{v:.1f}%\", va='center')\n",
    "    plt.title(\"Porcentaje de empresas según región\")\n",
    "    plt.xlabel(\"Porcentaje de empresas\")\n",
    "    plt.ylabel(\"Región\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358023b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Frecuencia y porcentaje por SECTOR ECONOMICO\n",
    "if \"sector_economico\" in df.columns:\n",
    "    freq_sector = df[\"sector_economico\"].value_counts()\n",
    "    print(freq_sector.head())\n",
    "\n",
    "    fig = plt.figure()\n",
    "    freq_sector.sort_values(ascending=True).plot(kind=\"barh\")\n",
    "    plt.title(\"Frecuencia de empresas según sector económico\")\n",
    "    plt.xlabel(\"Frecuencia de empresas\")\n",
    "    plt.ylabel(\"Sector Económico\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Porcentajes\n",
    "    perc_sector = (freq_sector / freq_sector.sum() * 100).sort_values(ascending=True)\n",
    "    fig = plt.figure()\n",
    "    perc_sector.plot(kind=\"barh\")\n",
    "    for i, v in enumerate(perc_sector.values):\n",
    "        plt.text(v, i, f\"{v:.1f}%\", va='center')\n",
    "    plt.title(\"Porcentaje de empresas según sector económico\")\n",
    "    plt.xlabel(\"Porcentaje de empresas\")\n",
    "    plt.ylabel(\"Sector Económico\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Frecuencia por sector económico y REPRO\n",
    "if \"sector_economico\" in df.columns and \"repro\" in df.columns:\n",
    "    crosstab = pd.crosstab(df[\"sector_economico\"], df[\"repro\"]).sort_index()\n",
    "    print(crosstab.head())\n",
    "\n",
    "    fig = plt.figure()\n",
    "    crosstab.plot(kind=\"bar\")\n",
    "    plt.title(\"Frecuencia de empresas por sector económico y REPRO\")\n",
    "    plt.xlabel(\"Sector Económico\")\n",
    "    plt.ylabel(\"Frecuencia de empresas\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc8b8c9",
   "metadata": {},
   "source": [
    "### 3. Desarrollo del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7013125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables requeridas para el modelo\n",
    "needed = [\"sector_economico\", \"entidad_otorgante_credito\", \"departamento\", \"saldo_insoluto\", \"repro\"]\n",
    "missing = [c for c in needed if c not in df.columns]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"No se puede entrenar el modelo. Faltan columnas clave: {missing}\")\n",
    "\n",
    "# Construcción de X, y\n",
    "base_features = [\"sector_economico\", \"entidad_otorgante_credito\", \"departamento\", \"saldo_insoluto\"]\n",
    "if \"cobertura_saldo_insoluto\" in df.columns:\n",
    "    base_features.append(\"cobertura_saldo_insoluto\")\n",
    "\n",
    "X = df[base_features].copy()\n",
    "y = df[\"repro\"].astype(int)\n",
    "\n",
    "# Split estratificado\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "cat_features = [\"sector_economico\", \"entidad_otorgante_credito\", \"departamento\"]\n",
    "num_features = [c for c in [\"saldo_insoluto\", \"cobertura_saldo_insoluto\"] if c in X.columns]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features),\n",
    "        (\"num\", StandardScaler(with_mean=False), num_features),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Logistic Regression con L1 + CV estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logit_cv = LogisticRegressionCV(\n",
    "    Cs=np.logspace(-3, 3, 10),\n",
    "    cv=cv,\n",
    "    penalty=\"l1\",\n",
    "    solver=\"saga\",\n",
    "    scoring=\"roc_auc\",\n",
    "    max_iter=5000,\n",
    "    n_jobs=-1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "pipe = Pipeline([(\"prep\", preprocess), (\"clf\", logit_cv)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "try:\n",
    "    best_C = pipe.named_steps[\"clf\"].C_[0]\n",
    "except Exception:\n",
    "    best_C = pipe.named_steps[\"clf\"].C_.ravel()[0]\n",
    "print(\"Mejor C (inverso de lambda) por validación cruzada:\", best_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas, ROC y principales coeficientes\n",
    "def get_feature_names(preprocess, X_fit):\n",
    "    names = []\n",
    "    for name, trans, cols in preprocess.transformers_:\n",
    "        if name == \"cat\":\n",
    "            ohe = trans\n",
    "            try:\n",
    "                fn = list(ohe.get_feature_names_out(cols))\n",
    "            except TypeError:\n",
    "                # Compatibilidad scikit-learn viejo\n",
    "                fn = [f\"{cols[i]}_{cat}\" for i, categories in enumerate(ohe.categories_) for cat in categories]\n",
    "            names.extend(fn)\n",
    "        elif name == \"num\":\n",
    "            if isinstance(cols, list):\n",
    "                names.extend(cols)\n",
    "            else:\n",
    "                names.append(cols)\n",
    "    return names\n",
    "\n",
    "# Predicciones y métricas\n",
    "y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"Matriz de confusión (test):\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de clasificación (test):\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"ROC AUC (test):\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "fig = plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC (test)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Coeficientes principales (valor absoluto)\n",
    "feature_names = get_feature_names(pipe.named_steps[\"prep\"], X_train)\n",
    "coefs = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": coefs})\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "top_n = 20\n",
    "top_df = coef_df.sort_values(\"abs_coef\", ascending=False).head(top_n)\n",
    "print(top_df)\n",
    "\n",
    "# Gráfico de coeficientes\n",
    "fig = plt.figure()\n",
    "y_pos = np.arange(len(top_df))\n",
    "plt.barh(y_pos, top_df[\"coef\"].values)\n",
    "plt.yticks(y_pos, top_df[\"feature\"].values)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(f\"Top {top_n} coeficientes (L1)\")\n",
    "plt.xlabel(\"Coeficiente\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614734c",
   "metadata": {},
   "source": [
    "### Notas de compatibilidad\n",
    "\n",
    "- **glmnet vs. scikit-learn**: `glmnet` usa \\(\\lambda\\) (fuerza de regularización). En `LogisticRegressionCV`, el parámetro equivalente es \\(C = 1/\\lambda\\). Aquí seleccionamos `C` por CV estratificada con `solver='saga'` y `penalty='l1'`.\n",
    "- **Codificación y escalado**: En R se usa `model.matrix`; en Python se replicó con `OneHotEncoder` para categóricas y `StandardScaler` para numéricas dentro de `ColumnTransformer`. Esto puede cambiar el conteo/nombre de variables y, por ende, la magnitud de coeficientes.\n",
    "- **Rutas y nombres de columnas**: Se agregó un diccionario de *alias* y una función que estandariza tildes y símbolos. Si un nombre no coincide, renómbralo o añade un alias.\n",
    "- **Umbral de decisión**: El reporte usa umbral 0.5. Para ajustar sensibilidad/especificidad, modifica el umbral, por ejemplo:\n",
    "\n",
    "  ```python\n",
    "  y_pred = (y_proba >= 0.35).astype(int)  # ejemplo\n",
    "  ```\n",
    "- **Hiperparámetros**: Ajusta la malla de `Cs` (e.g., `np.logspace(-4, 2, 20)`) o `max_iter`. Si el entrenamiento no converge, aumenta `max_iter` o estandariza mejor las variables.\n",
    "- **Desbalance de clases**: Considera `class_weight='balanced'` en `LogisticRegressionCV`, usar métricas como AUC-PR, o técnicas de *resampling* (SMOTE/undersampling). También puedes hacer *threshold moving* con el ROC/PR.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
