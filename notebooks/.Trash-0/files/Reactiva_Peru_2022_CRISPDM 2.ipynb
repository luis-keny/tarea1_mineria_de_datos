{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a345a6",
   "metadata": {},
   "source": [
    "# Reactiva Perú 2022 — Portado a Jupyter (Python) guiado por tu código R\n",
    "\n",
    "Este cuaderno **mantiene el formato de Jupyter** (mismas secciones) y **sustituye el código** por Python, siguiendo la intención del script R.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52a0a2",
   "metadata": {},
   "source": [
    "**Resultado del chequeo de finalidad:** equivalente ✅\n",
    "\n",
    "### Qué se detectó en tu script R\n",
    "- **Carga/Limpieza de datos**: detectado en R\n",
    "- **EDA/Gráficos**: detectado en R\n",
    "- **Tablas de contingencia**: detectado en R\n",
    "- **Modelo Lasso/logístico**: detectado en R\n",
    "- **Partición/validación**: detectado en R\n",
    "- **Métricas**: detectadas en R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716ad2e",
   "metadata": {},
   "source": [
    "## 1) Carga de librerías y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, unicodedata, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    s = unicodedata.normalize('NFD', s)\n",
    "    return ''.join(c for c in s if unicodedata.category(c) != 'Mn').lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc86ba",
   "metadata": {},
   "source": [
    "## 2) Importación de datos (equivalente al `read_excel` de R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bfd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca el archivo Excel de Reactiva en /mnt/data/\n",
    "excel_candidates = [p for p in glob.glob('/mnt/data/*.xlsx') if 'reactiva' in normalize(os.path.basename(p))]\n",
    "if not excel_candidates:\n",
    "    raise FileNotFoundError(\"No se encontró un archivo .xlsx con 'reactiva' en /mnt/data/.\")\n",
    "excel_path = excel_candidates[0]\n",
    "print(\"Usando archivo:\", excel_path)\n",
    "\n",
    "df = pd.read_excel(excel_path, engine='openpyxl')\n",
    "print(\"Dimensiones:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb444ace",
   "metadata": {},
   "source": [
    "## 3) Normalización de nombres de columnas y tipado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cols(cols):\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        c0 = normalize(str(c)).replace('/', '_').replace('(', '').replace(')', '').replace('.', '_')\n",
    "        c0 = '_'.join(c0.split())\n",
    "        out.append(c0)\n",
    "    return out\n",
    "\n",
    "df.columns = norm_cols(df.columns)\n",
    "\n",
    "aliases = {\n",
    "    \"ruc_o_dni\": [\"ruc_o_dni\", \"ruc_dni\", \"rucdni\", \"ruc__dni\"],\n",
    "    \"razon_social\": [\"razon_social\", \"razon_social_\"],\n",
    "    \"sector_economico\": [\"sector_economico\"],\n",
    "    \"saldo_insoluto\": [\"saldo_insoluto_s\", \"saldo_insoluto\", \"saldo_insoluto_s_\"],\n",
    "    \"cobertura_saldo_insoluto\": [\"cobertura_del_saldo_insoluto_s\", \"cobertura_saldo_insoluto_s\", \"cobertura_saldo_insoluto\"],\n",
    "    \"entidad_otorgante_credito\": [\"nombre_de_entidad_otorgante_del_credito\", \"entidad_otorgante_credito\"],\n",
    "    \"departamento\": [\"departamento\"],\n",
    "    \"repro\": [\"repro\"]\n",
    "}\n",
    "def pick_col(cands):\n",
    "    for col in cands:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "cols = {k: pick_col(v) for k,v in aliases.items()}\n",
    "cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf3def",
   "metadata": {},
   "source": [
    "## 4) EDA básico (gráficos/tablas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie de REPRO\n",
    "if cols[\"repro\"] and df[cols[\"repro\"]].notna().any():\n",
    "    repro = df[cols[\"repro\"]].astype(str).str.strip().str.upper().replace({'1':'SI','0':'NO'})\n",
    "    vc = repro.value_counts(dropna=False)\n",
    "    plt.figure()\n",
    "    plt.pie(vc.values, labels=vc.index.astype(str), autopct='%1.1f%%')\n",
    "    plt.title(\"Porcentaje de empresas con REPRO\")\n",
    "    plt.show()\n",
    "\n",
    "# Barras por Departamento\n",
    "if cols[\"departamento\"]:\n",
    "    s = df[cols[\"departamento\"]].value_counts().sort_values(ascending=True)\n",
    "    plt.figure()\n",
    "    plt.barh(s.index.astype(str), s.values)\n",
    "    plt.title(\"Frecuencia por Departamento\")\n",
    "    plt.xlabel(\"Frecuencia\"); plt.ylabel(\"Departamento\")\n",
    "    plt.show()\n",
    "\n",
    "# Tabla de contingencia Sector x REPRO\n",
    "if cols[\"sector_economico\"] and cols[\"repro\"]:\n",
    "    temp = df[[cols[\"sector_economico\"], cols[\"repro\"]]].copy()\n",
    "    temp[cols[\"repro\"]] = temp[cols[\"repro\"]].astype(str).str.strip().str.upper().replace({'1':'SI','0':'NO'})\n",
    "    ctab = pd.crosstab(temp[cols[\"sector_economico\"]], temp[cols[\"repro\"]])\n",
    "    ctab.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f4b6ba",
   "metadata": {},
   "source": [
    "## 5) Correlación (Spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7cf0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cols[\"saldo_insoluto\"] and cols[\"cobertura_saldo_insoluto\"]:\n",
    "    corr_spear = df[[cols[\"saldo_insoluto\"], cols[\"cobertura_saldo_insoluto\"]]].corr(method='spearman').iloc[0,1]\n",
    "    print(f\"Spearman(SALDO_INSOLUTO, COBERTURA_SALDO_INSOLUTO) = {corr_spear:.4f}\")\n",
    "else:\n",
    "    print(\"No se pudo calcular Spearman (faltan columnas numéricas).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c14ed",
   "metadata": {},
   "source": [
    "## 6) Modelo Lasso logístico con validación cruzada (equivalente a `cv.glmnet`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9e56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_for_model = [\"sector_economico\", \"entidad_otorgante_credito\", \"departamento\", \"saldo_insoluto\", \"repro\"]\n",
    "missing = [k for k in required_for_model if not cols[k]]\n",
    "if missing:\n",
    "    print(\"Modelo NO ejecutado: faltan columnas ->\", missing)\n",
    "else:\n",
    "    y_raw = df[cols[\"repro\"]]\n",
    "    if y_raw.dtype.kind in \"OUS\":\n",
    "        y = y_raw.astype(str).str.strip().str.upper().map({\"SI\":1, \"NO\":0, \"1\":1, \"0\":0})\n",
    "    else:\n",
    "        y = y_raw\n",
    "    if y.isna().any():\n",
    "        raise ValueError(\"REPRO contiene valores no mapeables a 0/1. Normaliza a {SI,NO} o {0,1}.\")\n",
    "\n",
    "    X = df[[cols[\"sector_economico\"], cols[\"entidad_otorgante_credito\"], cols[\"departamento\"], cols[\"saldo_insoluto\"]]].copy()\n",
    "    cat_cols = [cols[\"sector_economico\"], cols[\"entidad_otorgante_credito\"], cols[\"departamento\"]]\n",
    "    num_cols = [cols[\"saldo_insoluto\"]]\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", StandardScaler(), num_cols)\n",
    "    ])\n",
    "\n",
    "    clf = LogisticRegressionCV(\n",
    "        Cs=10,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=123),\n",
    "        penalty='l1',\n",
    "        solver='saga',\n",
    "        scoring='roc_auc',\n",
    "        max_iter=5000,\n",
    "        n_jobs=-1,\n",
    "        refit=True\n",
    "    )\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    pipe = Pipeline([(\"pre\", pre), (\"clf\", clf)])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=123)\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "    y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = (cm[0,0] + cm[1,1]) / cm.sum()\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    print(\"Matriz de confusión:\\n\", cm)\n",
    "    print(f\"Accuracy: {acc:.4f} | ROC-AUC: {auc:.4f}\")\n",
    "    print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    # Coeficientes no nulos (interpretación del lasso)\n",
    "    ohe = pipe.named_steps[\"pre\"].named_transformers_[\"cat\"]\n",
    "    feature_names = list(ohe.get_feature_names_out(cat_cols)) + num_cols\n",
    "    coefs = pipe.named_steps[\"clf\"].coef_.ravel()\n",
    "    nz = [(n, w) for n, w in zip(feature_names, coefs) if abs(w) > 1e-8]\n",
    "    for name, w in sorted(nz, key=lambda x: abs(x[1]), reverse=True)[:30]:\n",
    "        print(f\"{name:60s} {w: .4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0536d44b",
   "metadata": {},
   "source": [
    "## 7) Notas de compatibilidad y qué haría falta si algo no coincide\n",
    "\n",
    "- **Finalidad**: tu flujo en R y este en Python son **equivalentes** (carga → EDA → tablas → correlación → Lasso CV).  \n",
    "- Si en tu R hay **transformaciones específicas** (por ejemplo, crear `REPRO` a partir de otra columna, imputaciones o filtros), agrégalas **antes** del bloque de modelado.  \n",
    "- Si tu R usa **métricas distintas** o **otro umbral** (p.ej. 0.4 en vez de 0.5), ajusta la línea `y_pred = (y_prob > 0.5)`.  \n",
    "- Si tu R balancea clases (SMOTE/weights), en Python podrías usar `class_weight='balanced'` en `LogisticRegressionCV`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
