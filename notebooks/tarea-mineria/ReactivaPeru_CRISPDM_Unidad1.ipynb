{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reactiva Perú – Reprogramación de Créditos\n",
        "## Unidad 1: Perfil del Proyecto y Dataset Preprocesado (CRISP-DM)\n",
        "\n",
        "**Autores:** [Agrega tus nombres]\n",
        "\n",
        "**Curso:** Minería de Datos\n",
        "\n",
        "**Fecha:** 2025-09-08\n",
        "\n",
        "---\n",
        "Este cuaderno implementa la primera entrega del proyecto siguiendo **CRISP-DM**:\n",
        "1) Comprensión del negocio.\n",
        "2) Comprensión y preparación de los datos.\n",
        "3) Planificación del modelado.\n",
        "4) Entrega de dataset limpio y documentado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Perfil del Proyecto\n",
        "\n",
        "### 1.1 Título\n",
        "Análisis y predicción de la reprogramación de créditos de Reactiva Perú mediante técnicas de minería de datos\n",
        "\n",
        "### 1.2 Problema / Caso de negocio\n",
        "El programa Reactiva Perú otorgó créditos con garantía estatal a empresas para sostener su capital de trabajo durante la pandemia. Una proporción relevante de empresas reprogramó sus créditos. Interesa identificar factores asociados a la reprogramación y preparar un dataset que permita, en fases posteriores, construir modelos predictivos.\n",
        "\n",
        "### 1.3 Propósito / Valor esperado\n",
        "- Detectar patrones asociados a la reprogramación de créditos.\n",
        "- Entregar un dataset limpio y estructurado apto para modelado.\n",
        "- Sentar bases para modelos de clasificación en fases siguientes.\n",
        "\n",
        "### 1.4 Justificación\n",
        "- Evaluar la eficacia del programa frente a la crisis.\n",
        "- Reconocer sectores/regiones con mayor vulnerabilidad.\n",
        "- Aplicar técnicas de minería de datos en un caso real con valor público.\n",
        "\n",
        "### 1.5 Objetivos\n",
        "**General:** Analizar y preparar datos de Reactiva Perú para explicar y predecir reprogramación de créditos.\n",
        "\n",
        "**Específicos:**\n",
        "\n",
        "1. Describir el contexto y variables del dataset.\n",
        "\n",
        "2. Aplicar limpieza, transformación y documentación del dataset (ETL/ELT).\n",
        "\n",
        "3. Planificar técnicas de modelado (clasificación) y métricas de evaluación.\n",
        "\n",
        "\n",
        "### 1.6 Alcance\n",
        "Se trabaja con datos públicos del MEF sobre reprogramación de créditos. No se usa información financiera privada ni se realiza análisis macroeconómico completo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Metodología: CRISP-DM\n",
        "\n",
        "1) **Comprensión del negocio:** definición del problema y objetivos.\n",
        "2) **Comprensión de los datos:** inventario de variables, calidad de datos, distribución.\n",
        "3) **Preparación de datos:** limpieza, transformación, codificación, reducción.\n",
        "4) **Modelado (planificación):** propuesta de algoritmos y métricas.\n",
        "5) **Evaluación (planificación):** criterios: precisión, recall, F1.\n",
        "6) **Despliegue (futuro):** uso para decisiones públicas/financieras.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 3. Configuración e importaciones\nimport os\nimport sys\nimport math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npd.set_option('display.max_columns', 120)\npd.set_option('display.width', 160)\n\nprint('Versiones -> pandas:', pd.__version__, '| numpy:', np.__version__)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 4. Ruta de datos y carga\n# Ajusta la ruta y el nombre de archivo si corresponde.\n# Se soporta un único Excel o una lista de archivos para concatenación.\n\nRUTA_DATOS = './'  # cambia si el archivo está en otra carpeta\nARCHIVOS_EXCEL = [\n    'reactiva_peru_2022.xlsx'  # ejemplo: reemplaza por el nombre real si es distinto\n]\n\n# Lectura y concatenación\nframes = []\nfor f in ARCHIVOS_EXCEL:\n    path = os.path.join(RUTA_DATOS, f)\n    if not os.path.exists(path):\n        print('Advertencia: no se encontró', path)\n    else:\n        frames.append(pd.read_excel(path))\n\nif frames:\n    df_raw = pd.concat(frames, ignore_index=True)\nelse:\n    # fallback: crear un df vacío para no romper el cuaderno\n    df_raw = pd.DataFrame()\n\nprint('Forma del dataset original:', df_raw.shape)\ndf_raw.head(3)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Comprensión de los Datos – Diccionario inicial\n",
        "\n",
        "Documentar variables clave. Completar el CSV `diccionario_variables.csv` generado al final de este cuaderno.\n",
        "\n",
        "Variables típicas en Reactiva Perú (ajustar según columnas reales):\n",
        "\n",
        "- ORDEN: índice interno del registro.\n",
        "\n",
        "- RAZÓN SOCIAL: nombre de la empresa (identificador, no se usa para modelado).\n",
        "\n",
        "- RUC/DNI: identificador numérico de la empresa (no para modelado).\n",
        "\n",
        "- SECTOR ECONÓMICO: rubro de la empresa.\n",
        "\n",
        "- DEPARTAMENTO: ubicación geográfica.\n",
        "\n",
        "- ENTIDAD FINANCIERA: banco o financiera otorgante.\n",
        "\n",
        "- SALDO INSOLUTO: monto pendiente de pago.\n",
        "\n",
        "- COBERTURA SALDO INSOLUTO: monto garantizado por el Estado.\n",
        "\n",
        "- REPROGRAMACIÓN: indicador de si el crédito fue reprogramado (Sí/No).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 6. Auditoría de calidad de datos\nprint('Columnas:', list(df_raw.columns))\nprint('\\nTipos de datos:')\nprint(df_raw.dtypes)\n\nprint('\\nValores nulos por columna:')\nprint(df_raw.isna().sum())\n\n# Duplicados (considera todas las columnas para detectar duplicados idénticos)\nduplicados = df_raw.duplicated().sum() if not df_raw.empty else 0\nprint('\\nDuplicados totales:', duplicados)\n\n# Estadísticos básicos para numéricas\nnum_cols = df_raw.select_dtypes(include=[np.number]).columns.tolist()\nif num_cols:\n    display(df_raw[num_cols].describe())\nelse:\n    print('No hay columnas numéricas detectadas.')\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 7. EDA básica (sin librerías externas, solo matplotlib)\n\n# Distribución de una variable numérica clave (ajustar nombre si difiere)\ncol_monto = None\nfor c in df_raw.columns:\n    if 'SALDO' in c.upper() or 'MONTO' in c.upper():\n        col_monto = c\n        break\n\nif col_monto is not None:\n    plt.figure(figsize=(7,4))\n    df_raw[col_monto].dropna().astype(float).plot(kind='hist', bins=40)\n    plt.title(f'Distribución de {col_monto}')\n    plt.xlabel(col_monto)\n    plt.ylabel('Frecuencia')\n    plt.show()\nelse:\n    print('No se encontró columna de monto o saldo para histograma.')\n\n# Conteo por sector económico (o variable categórica relevante)\ncat_col = None\ncandidates = ['SECTOR', 'SECTOR ECONÓMICO', 'SECTOR_ECONOMICO']\nupper_cols = {c.upper(): c for c in df_raw.columns}\nfor cand in candidates:\n    if cand in upper_cols:\n        cat_col = upper_cols[cand]\n        break\n\nif cat_col is not None:\n    conteo = df_raw[cat_col].astype(str).value_counts().head(15)\n    plt.figure(figsize=(8,4))\n    conteo.plot(kind='bar')\n    plt.title(f'Top 15 categorías en {cat_col}')\n    plt.xlabel(cat_col)\n    plt.ylabel('Frecuencia')\n    plt.tight_layout()\n    plt.show()\nelse:\n    print('No se encontró columna de sector económico para gráfico de barras.')\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 8. Preparación de datos: limpieza\n\ndf = df_raw.copy()\n\n# Estandarización de nombres de columnas\ndf.columns = [str(c).strip().replace('\\n',' ').replace('  ',' ') for c in df.columns]\n\n# Eliminación de duplicados exactos\ndf = df.drop_duplicates().reset_index(drop=True)\n\n# Conversión de posibles montos a numérico (intenta detectar columnas con 'SALDO' o 'MONTO')\nfor c in df.columns:\n    if any(k in c.upper() for k in ['SALDO', 'MONTO']):\n        # Quitar comas, espacios y símbolos si existen, luego convertir\n        df[c] = (\n            df[c]\n            .astype(str)\n            .str.replace('[^0-9\\.-]', '', regex=True)\n            .replace({'': np.nan, '-': np.nan})\n        )\n        df[c] = pd.to_numeric(df[c], errors='coerce')\n\n# Tratamiento de nulos básicos: ejemplo simple (ajustar a criterio)\n# Regla: si una columna numérica tiene pocos nulos, rellenar con mediana; si muchos nulos, evaluar descartar\nthreshold = 0.3  # 30% tolerancia\nfor c in df.columns:\n    null_rate = df[c].isna().mean()\n    if df[c].dtype.kind in 'biufc':  # numérica\n        if null_rate > 0 and null_rate <= threshold:\n            df[c] = df[c].fillna(df[c].median())\n    else:\n        # Categóricas: rellenar nulos con 'DESCONOCIDO' si es bajo el umbral\n        if null_rate > 0 and null_rate <= threshold:\n            df[c] = df[c].fillna('DESCONOCIDO')\n\n# Eliminación de columnas con demasiados nulos\ncols_to_drop = [c for c in df.columns if df[c].isna().mean() > 0.6]\ndf = df.drop(columns=cols_to_drop)\n\nprint('Columnas eliminadas por nulos > 60%:', cols_to_drop)\nprint('Forma tras limpieza:', df.shape)\ndf.head(3)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 9. Preparación de datos: selección y codificación\n\n# Identificadores a descartar del modelado\nid_like = []\nfor c in df.columns:\n    cu = c.upper()\n    if any(k in cu for k in ['RUC', 'DNI', 'RAZON', 'RAZÓN', 'ORDEN', 'NOMBRE']):\n        id_like.append(c)\n\ndf_model = df.drop(columns=id_like, errors='ignore')\n\n# Variable objetivo: REPROGRAMACIÓN (ajustar a nombre real)\ny_col = None\nfor c in df.columns:\n    if 'REPRO' in c.upper():\n        y_col = c\n        break\n\nif y_col is not None:\n    # Convertir a binaria 1/0 si es texto\n    if df_model[y_col].dtype == object:\n        df_model[y_col] = df_model[y_col].str.strip().str.upper().map({'SI':1, 'SÍ':1, 'YES':1, 'Y':1, '1':1, 'NO':0, 'N':0, '0':0})\n    # Asegurar tipo numérico\n    df_model[y_col] = pd.to_numeric(df_model[y_col], errors='coerce')\n\n# One-Hot Encoding para categóricas\ncat_cols = df_model.select_dtypes(include=['object']).columns.tolist()\ndf_model = pd.get_dummies(df_model, columns=cat_cols, dummy_na=False)\n\nprint('Forma dataset de modelado (temporal):', df_model.shape)\ndf_model.head(3)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 10. Normalización opcional de variables numéricas (no se aplica a la variable objetivo)\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nif 'y_col' in locals() and y_col in df_model.columns:\n    features = [c for c in df_model.columns if c != y_col]\nelse:\n    features = df_model.columns.tolist()\n\nscaler = MinMaxScaler()\ndf_scaled = df_model.copy()\ndf_scaled[features] = scaler.fit_transform(df_model[features])\n\nprint('Forma del dataset escalado:', df_scaled.shape)\ndf_scaled.head(3)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 11. Guardado de artefactos\n#  - Dataset limpio (df)\n#  - Dataset modelado (df_model)\n#  - Dataset escalado (df_scaled)\n#  - Diccionario de variables (plantilla)\n\nOUTPUT_DIR = './salidas_unidad1'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\npath_clean = os.path.join(OUTPUT_DIR, 'reactiva_clean.csv')\npath_model = os.path.join(OUTPUT_DIR, 'reactiva_model.csv')\npath_scaled = os.path.join(OUTPUT_DIR, 'reactiva_scaled.csv')\n\ndf.to_csv(path_clean, index=False, encoding='utf-8')\ndf_model.to_csv(path_model, index=False, encoding='utf-8')\ndf_scaled.to_csv(path_scaled, index=False, encoding='utf-8')\n\nprint('Guardado:')\nprint(' -', path_clean)\nprint(' -', path_model)\nprint(' -', path_scaled)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 12. Plantilla de diccionario de variables y tratamientos\ncols = list(df_raw.columns)\ntemplate = pd.DataFrame({\n    'variable_original': cols,\n    'descripcion': [''] * len(cols),\n    'tipo_dato': ['numerica/categorica/fecha'] * len(cols),\n    'tratamientos_aplicados': ['limpieza/codificacion/normalizacion/otra'] * len(cols),\n    'observaciones': [''] * len(cols)\n})\nDICT_PATH = os.path.join(OUTPUT_DIR, 'diccionario_variables.csv')\ntemplate.to_csv(DICT_PATH, index=False, encoding='utf-8')\nprint('Plantilla creada:', DICT_PATH)\ntemplate.head(10)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Planificación para el Modelado\n",
        "\n",
        "Problema de clasificación binaria: predecir la reprogramación del crédito.\n",
        "Modelos candidatos: Regresión Logística, Árboles de Decisión, Random Forest.\n",
        "Métricas: precisión, recall, F1-score. Validación con train/test split o validación cruzada.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# 13.1 División de datos (borrador para próxima unidad)\nfrom sklearn.model_selection import train_test_split\n\nif 'y_col' in locals() and y_col in df_scaled.columns:\n    X = df_scaled.drop(columns=[y_col])\n    y = df_scaled[y_col].fillna(0).astype(int)  # fallback simple\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\nelse:\n    print('No se detectó variable objetivo de reprogramación. Define la columna que indica REPRO.')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Conclusiones iniciales\n",
        "\n",
        "1) Se documentó el contexto y los objetivos del proyecto.\n",
        "2) Se auditó la calidad de datos y se aplicaron reglas básicas de limpieza.\n",
        "3) Se generó un dataset limpio y versiones transformadas aptas para modelado.\n",
        "4) Se dejó preparado el pipeline para partición de datos y futura etapa de modelado.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}